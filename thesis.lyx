#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass llncs
\begin_preamble
\usepackage{calc}
\usepackage{graphicx}
\graphicspath{{.//}}


\usepackage{fancyhdr}
\pagestyle{fancyplain}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0pt}
\end_preamble
\options final
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics pdftex
\default_output_format pdf2
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Optimizing Storage of Energy Event Data in In-Memory Databases"
\pdf_author "Leonhard Schweizer"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\listings_params "numberbychapter=false"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.1cm}
\end_layout

\begin_layout Plain Layout


\backslash
LARGE Bachelor's Thesis
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.25cm} 	
\end_layout

\begin_layout Plain Layout


\backslash
Huge Optimizing Storage of Energy Event Data in In-Memory Databases
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\end_layout

\begin_layout Plain Layout


\backslash
large Optimierte Ablage von Energieereignisdaten in Hauptspeicherdatenbanken
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\end_layout

\begin_layout Plain Layout


\backslash
large
\end_layout

\begin_layout Plain Layout


\backslash
vspace{1.0cm} 	
\end_layout

\begin_layout Plain Layout


\backslash
LARGE 
\backslash
textbf{Leonhard Schweizer}
\backslash

\backslash
 
\backslash
normalsize
\end_layout

\begin_layout Plain Layout

leonhard.schweizer@student.hpi.uni-potsdam.de
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\end_layout

\begin_layout Plain Layout


\backslash
small Hasso Plattner Institute for IT Systems Engineering
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Enterprise Platform and Integration Concepts Chair
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename figures/hpi_logo.pdf

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\end_layout

\begin_layout Plain Layout

August-Bebel-Str.
 88
\backslash

\backslash
 	
\end_layout

\begin_layout Plain Layout

14482 Potsdam, Germany
\backslash

\backslash
 	
\end_layout

\begin_layout Plain Layout


\backslash
url{http://epic.hpi.uni-potsdam.de/}
\backslash

\backslash
 	
\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}  
\end_layout

\begin_layout Plain Layout

Supervisors: 
\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\backslash

\backslash
  
\end_layout

\begin_layout Plain Layout

Dr.
 Alexander Zeier
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Matthieu-P.
 Schapranow
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

Christian Schwarz  
\end_layout

\begin_layout Plain Layout


\backslash
vspace{0.5cm}
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

Hasso Plattner Institute
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

Potsdam, Germany  
\end_layout

\begin_layout Plain Layout


\backslash
vspace{1.0cm}
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

June 30th, 2011 
\backslash
end{center} 
\end_layout

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setcounter{page}{1}
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
abstractname}{Zusammenfassung.}
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
In the course of the ongoing implementation of smart metering in Germany,
 residential customers alone will produce roughly 1.4 trillion records per
 year through their power meters.
 In other words, energy providers will have to deal with 1.8GB of raw data
 every 15 minutes, which is the default measurement interval of modern metering
 devices.
 The processing of continuous data streams of this dimension is a big challenge
 today and traditional OLAP systems aren't capable of analysing this huge
 amount of data in real-time.
 Thus, meter readings are sent to the providers at most once per day and
 analytical possibilities remain unused.
 This thesis describes an approach to the real-time processing of energy
 event data.
 By chosing an in-memory database as storage it can be processed and analyzed
 simultaneously while notably reducing the amount of required space at the
 same time through the utilization of compression potentials in column-based
 tables.
 As a result, new opportunities arise, like offering electricity rates with
 real-time pricing or managing supply and demand based on up-to-the-minute
 analytics.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
abstractname}{Abstract.}
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
In the course of the ongoing implementation of smart metering in Germany,
 residential customers alone will produce roughly 1.4 trillion records per
 year through their power meters.
 In other words, energy providers will have to deal with 1.8GB of raw data
 every 15 minutes, which is the default measurement interval of modern metering
 devices.
 The processing of continuous data streams of this dimension is a big challenge
 today and traditional OLAP systems aren't capable of analysing this huge
 amount of data in real-time.
 Thus, meter readings are sent to the providers at most once per day and
 analytical possibilities remain unused.
 This thesis describes an approach to the real-time processing of energy
 event data.
 By chosing an in-memory database as storage it can be processed and analyzed
 simultaneously while notably reducing the amount of required space at the
 same time through the utilization of compression potentials in column-based
 tables.
 As a result, new opportunities arise, like offering electricity rates with
 real-time pricing or managing supply and demand based on up-to-the-minute
 analytics.
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Traditionally, database management systems are split into two categories
 
\begin_inset CommandInset citation
LatexCommand cite
key "journals/dbsk/KrugerGTEZP10"

\end_inset

.
 On the one hand, there are write-optimized, row oriented Online Transactional
 Processing (OLTP) systems, which in return lack analytical performance.
 On the other hand, there are read-optimized Online Analytical Processing
 (OLAP) systems, which aren't suitable for transactional processing.
 
\end_layout

\begin_layout Standard
This is one of the reasons why utility companies today aren't capable to
 take full advantage of the data flood arising from a future nationwide
 smart metering infrastructure.
 For instance, the growing importance of renewable and distributed energy
 sources like wind and solar energy as part of the aimed at energy turnaround
 leads to an increased need of information.
 Despite their unpredictable nature, energy providers will have to provide
 available-to-promise functions.
 While a smart grid will deliver the required data, there are no systems
 that enable the involved parties to gain the information which is neccesary
 to balance the short-term demand and the volatile energy input of renewable
 energy sources out of it in real-time.
\end_layout

\begin_layout Standard
At the same time, suppliers of electric energy are forced to offer new contract
 conditions and tariff models to their customers.
 Traditionally, consumers have to pay a fixed rate every month regardless
 of the actual consumption until rates can be adjusted accordingly when
 their power meters are read manually once per year.
 To increase cost transparency to consumers, billing intervals are supposed
 to be shortened to months at least 
\begin_inset CommandInset citation
LatexCommand cite
key "KOMMISSION_2011"

\end_inset

.
 But automated meter reading even offers the data to shorten this interval
 even further, e.g.
 to days or hours.
 Such short billing intervals in turn enable the consumers to change tariffs
 or energy providers with a much higher frequency as compared to the long
 minimum contract durations offered today.
 Again, technical insufficiencies are the primary reason why this isn't
 already happening.
\end_layout

\begin_layout Standard
With the introduction of in-memory databases, the promise has been made
 that the separation of OLTP and OLAP systems becomes superfluous, in particular
 with the help of column oriented tables 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/sigmod/Plattner09"

\end_inset

 - a technique that was originally introduced as highly read-optimized approach
 by Stonebreaker et.
 al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Stonebraker:2005:CCD:1083592.1083658"

\end_inset

.
 In-memory technology has the potential to close the gap between the real-time
 capturing of the data amassing in a smart metering infrastructure and the
 real-time acquisition of information out of this data.
 In this thesis, it is shown how an in-memory database can be utilized to
 process and store the amount of meter readings which are assumed to arise
 after a Germany-wide implementation of smart metering and how the memory
 footprint of this data can be minimized with the help of lightweight column
 compression techniques with the help of SAPs In-Memory Computing Engine.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Simulation of an Advanced Metering Infrastructure
\end_layout

\begin_layout Standard
As an extensive rollout of smart metering devices and the corresponding
 metering infrastructure hasn't taken place yet in Germany, a simulation
 had to be used to generate a constant event stream of significant scale
 in order to allow for the evaluation of its processing and analysis.
 In this chapter, the characteristics of such an infrastructure are depicted
 as well as the mapping of this infrastructure to the simulation model.
 Finally, the experiences gained from the execution of the simulation system
 are summarized in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Simulation-Environment-Execution"

\end_inset

.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:AMI"

\end_inset

Characteristics of an Advanced Metering Infrastructure
\end_layout

\begin_layout Standard
The smart metering infrastructure is still in the early stages of development
 in Europe.
 While the installation of smart electricity and gas meters recently became
 required by law in Germany for newly constructed buildings and in the case
 of total refurbishments 
\begin_inset CommandInset citation
LatexCommand cite
key "EnWG21b"

\end_inset

, the automated reading of power meters is only realized in a few small
 model regions.
 There is no Germany-wide metering infrastructure.
 However, there seems to be a broad consent to the characteristics such
 an architecture has to feature 
\begin_inset CommandInset citation
LatexCommand cite
key "openmeter/requirements,McLaughlin:2009:ETA:1880551.1880566,Ronald-1"

\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AMI"

\end_inset

 depicts the most important components using the FMC notation 
\begin_inset CommandInset citation
LatexCommand cite
key "FMC"

\end_inset

.
\end_layout

\begin_layout Standard
In this architecture, which is commonly referred to as Advanced Metering
 Infrastructure (AMI), every household is equipped with a smart meter.
 Smart meters are digital meters which are equipped with a CPU, storage
 and communication interfaces.
 They collect information about the recent energy consumption in fixed time
 intervals, e.g.
 quarters of an hour, and send it to the energy provider for billing purposes.
 The smart meters are connected to intermediary data collectors which concentrat
e the meter readings before forwarding them to the utility companies.
 The connections between smart meters, collectors and the utility companies
 can be established via various channels, like ethernet, powerline communication
 or GSM.
\end_layout

\begin_layout Standard
Since standardization is not well advanced in the field of smart metering,
 it is safe to assume that smart meters from different manufacturers will
 use different data formats.
 Therefore, so-called Meter Data Unification and Synchronization (MDUS)
 systems are introduced in order to harmonize the different protocols of
 different vendors.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/ami.svg
	width 90col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:AMI"

\end_inset

The Advanced Metering Infrastrucutre as depicted in 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/lcn/SchapranowKZP10"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Simulation Requirements
\end_layout

\begin_layout Standard
Since the data generated by the simulated smart meters should not only be
 used for stress testing, but also for real-time analyses and visualization,
 various requirements had to be met by the simulation system.
\end_layout

\begin_layout Standard
The system had to be capable to simulate at least 100 million smart meters,
 each initiating one reading event per 15 minutes.
 Furthermore, the number of simulated metering devices should be freely
 configurable.
 Thus, the system can not only be used to simulate divergent numbers of
 customers for energy providers of different size, but also to simulate
 the projected total amount of events in the future smart grid of Germany.
\end_layout

\begin_layout Standard
In avoidance of unfavorable and advantageous effects of random data, for
 instance on compression rates, and with regard to data analysis and visualizati
on tests, the generated readings should be based on real power consumption
 data.
 Furthermore, the simulation should be aware of single smart meters.
 That means that for a given meter id, reading events should occur in 15
 minute intervals.
 Besides, the unity of all readings of any simulated smart meter should
 form a realistic consumption behaviour over extended periods of time, e.g.
 days, weeks, months and years.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:AMI-Implementation"

\end_inset

Implementation
\end_layout

\begin_layout Standard
The simulation of an Advanced Metering Infrastructure has been split up
 into three components, which are depicted in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation"

\end_inset

.
 However, not all parts of the AMI have a counterpart.
 Namely the Meter Data Unification and Synchronization (MDUS) system is
 missing, since there is no gain in simulating different vendor specific
 protocols and data formats.
 In the first place, the MDUS systems don't have to store data, in fact
 they transform it.
 That means that in order to scale, only the throughput has to be enhanced,
 which can be achieved easily by additional hardware and parallelisation.
 Therefore, the MDUS system should not constitue the AMIs limiting factor.
\end_layout

\begin_layout Standard
To a greater degree, the database which has to process, to store and to
 analyse all readings is the bottleneck of the whole system.
 At this point, scaling can not be reached simply by adding more hardware,
 in the sense of multiplying database hosts and instances.
 For example, all instances would have to be utilized for analytical queries
 like the overall consumption of all customers, with the effect that the
 partitioning of the data doesn't necessarily result in a lower overall
 load for each single instance.
\end_layout

\begin_layout Standard
Thus, the primary target of the simulation is the generation of huge amounts
 of insert load rather than a realistic representation of the AMI.
 In this way, the limits of an in-memory based central system can be investigate
d.
 All other components of the metering infrastructure can be scaled easily,
 which is the reason why this paper focuses on the performance of the database
 system itself.
\end_layout

\begin_layout Standard
In the following, the data producer constituting the smart metering component
 of the AMI, the concentrator, which embodies the event aggregation component
 and the database client as representation of the interface of the industry-spec
ific enterprise application are described in detail.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/data-simulator.svg
	width 90col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Simulation"

\end_inset

Components of the AMI simulation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data Producer
\end_layout

\begin_layout Standard
An instance of the data producer, which is implemented as Java executable,
 represents any number of smart meters.
 One instance of the data producer can connect to exactly one concentrator.
 A dedicated, persistent TCP/IP connection is built between the data producer
 and a concentrator for each thread the data producer is spawning.
 One thread simulates up to 375,000 smart meters.The number of smart meters
 that can be simulated by a single instance is mostly limited by the number
 of threads the host system is capable to handle and the network capacity.
\end_layout

\begin_layout Standard
The data producer expects two main input parameters: An initial timestamp,
 which defaults to the current local time, and a standard load profile,
 which defaults to the H0 profile published by the BDEW
\begin_inset Foot
status open

\begin_layout Plain Layout
German Energy and Water Association, www.bdew.de
\end_layout

\end_inset

.
 Such profiles contain the average consumption of a specific customer base
 (which are residential customers in the case of the H0 profile) over a
 period of one or more years.
 They consist of counter readings or consumption deltas in 15 minute intervals,
 yielding 35040 values for non-leapyears.
 For the reasons depicted in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Compression-of-Energy"

\end_inset

, consumption deltas are preferred over counter readings.
\end_layout

\begin_layout Standard
Based on these two input parameters, readings are generated.
 The initial timestamp is used to calculate the current simulated day and
 time.
 The according consumption value is read from the standard load profile.
 A uniformly distributed variance is added to this value 
\begin_inset Formula $v$
\end_inset

 for every generated reading 
\begin_inset Formula $r_{\mathrm{{v}}}$
\end_inset

 such that 
\begin_inset Formula $0\leq v-0,20\cdot v\leq r_{\mathrm{{v}}}\leq v+0,20\cdot v$
\end_inset

.
 The timestamp of the generated reading is rounded down to 15 minute intervals.
 For instance, 13:14:55 would be replaced by 13:00:00 (cf.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Compression-of-Energy"

\end_inset

).
\end_layout

\begin_layout Standard
The third and last component of a reading is the unique integer device id
 by which every simulated smart meter can be identified.
 Each smart meter is associated with one customer, and each customer can
 have an arbitrary number of smart meters.
 This mapping information is not part of the table containing the meter
 readings.
\end_layout

\begin_layout Standard
The data producer generates discrete reading events for each of these identifier
s every 15 minutes and sends them to the assigned concentrator instantly.
 The identifiers are spread randomly accross the 15 minute intervall, but
 keep their time slot across multiple intervals as long as the simulation
 is running.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Sample-readings"

\end_inset

 shows one hour of readings for a given smart meter.
\end_layout

\begin_layout Standard
Since the simulation is executed over an ethernet network via TCP/IP, data
 loss is of no concern and the push architecture described here could be
 favored over the pull approach which dominates in real world metering infrastru
ctures.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Sample-readings"

\end_inset

Sample readings generated by the data producer
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle" tabularwidth="60col%">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Smart Meter ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timestamp
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Value [Wh]
\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32202775
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1306612800
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
36
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32202775
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1306613700
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
37
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32202775
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1306614600
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32202775
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1306615500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Concentrator
\end_layout

\begin_layout Standard
Just like the data producer, the concentrator is implemented as Java executable.
 Its purpose is to aggregate events and to forward these aggregated batches
 to a database client, reducing the number of connections and insert events
 visible to the central database system.
\end_layout

\begin_layout Standard
A concentrator accepts any number of TCP/IP connections from any number
 of data producers.
 The concentrator can connect to one or more database clients, again via
 TCP/IP.
 The primary reason for supporting multiple database clients is the evaluation
 of distributed database systems, which is the subject of another thesis
 
\begin_inset CommandInset citation
LatexCommand cite
key "sten"

\end_inset

.
 In this case, the concentrator is provided with the data partitioning instructi
ons and forwards the readings to the proper destination database instance.
\end_layout

\begin_layout Standard
The concentrator collects incoming readings until the batch size reaches
 a configurable threshold (default: 100,000 readings) or the oldest reading
 in the batch exceeds a certain age (default: 5 minutes).
 Once this happens, the batch of readings gets converted into a column-wise
 fashion and is sent to the corresponding database client together with
 the number of readings contained in the batch.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Concentrator-Output"

\end_inset

 illustrates this conversion with the aid of the first two records of the
 row based data shown in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Sample-readings"

\end_inset

.
 The resulting column based format is very beneficial for inserting data
 into column based tables.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/row-data.png
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/column-data.png
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Concentrator-Output"

\end_inset

The first two records from Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Sample-readings"

\end_inset

 in row format and formated as output of a concentrator
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Database Client
\end_layout

\begin_layout Standard
The main purpose of the database client is to expose a specialised interface
 for inserting batches of readings into the in-memory database, the back-end
 of the simulation system.
\end_layout

\begin_layout Standard
It accepts TCP/IP connections from an arbitrary number of concentrators
 and inserts the incoming batches into the database in a non-blocking fashion.
 Thus, it can be avoided that the database client becomes the bottleneck
 of the system rather then the database itself.
 Since the concentrators already convert the readings into the desired format,
 no additional transformations of the data have to be carried out by the
 database client.
 The measures that have been taken to speed up the process of inserting
 as much as possible in order to reduce the overall load of the database
 and to enable the simultaneous processing of analytical requests are presented
 in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Acceleration-of-INSERT"

\end_inset

.
\end_layout

\begin_layout Standard
Since the database client is intended for running on the same host as the
 database system, it is important to reduce the footprint of the client.
 For that reason, the client is implemented as C++ native executable and
 connected to the database via ODBC.
 The C++ implementation reduces the main memory consumption from a maximum
 of 2.2GB to 110MB compared to a corresponding Java implementation.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Simulation-Environment-Execution"

\end_inset

Simulation Environment and Execution
\end_layout

\begin_layout Standard
According to the Federal Statistical Office there are 40.2 million households
 and 3.6 million businesses in Germany 
\begin_inset CommandInset citation
LatexCommand cite
key "DestatisHouseholds,DestatisCompanies"

\end_inset

.
 Since many companies have branches at multiple locations and huge branches
 will be equipped with multiple smart meters, the total number of smart
 meters is assumed to be around 60 million for non-residential customers.
 Thus, a total of 100 million smart meters can be expected after a nationwide
 rollout of smart meters in Germany.
 For that reason, the primary goal of the simulation is to generate the
 load of 100 million smart meters which send meter readings in 15 minute
 intervals.
\end_layout

\begin_layout Standard
For the generation of the meter readings, four workstations with equipment
 equivalent to host HPC are used.
 On each of them, one single instance of the data producer is running, simulatin
g 25 million smart meters.
 The data producer is connected to exactly one concentrator which is running
 on the same host.
 Since the simulated smart meters are distributed uniformly accross the
 15 minute interval, each concentrator receives roughly 28,000 meter readings
 per second.
 Each concentrator is connected to a dedicated instance of the database
 client which is running on the host of the database HPB and inserting incoming
 readings into an instance of the Table READINGS_RLE (cf.
 Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Table-READINGS_RLE"

\end_inset

).
 
\end_layout

\begin_layout Standard
The frequency of incoming data events is dependent on the batch size of
 the concentrator.
 Lower batch sizes lead to a smooth CPU workload on the database system
 but result in a higher overhead due to the increased number of executed
 INSERT statements.
 When using 10,000 as batch size, every concentrator forwards data more
 than twice per second.
 The result is a constant CPU utilization of 40%-80% through the database.
 In contrast, a batch size of 1,000,000 leads to peaks of 170% when data
 packets are received from a concentrator every 36 seconds.
 During this interval, there is no CPU load caused by the insertion of new
 readings.
 In both cases, the CPU load increases up to 300% during executions of the
 merge process, since the test system is configured to utilize at most three
 cores during this task.
\end_layout

\begin_layout Standard
For the purpose of planning security, a smooth ressource utilization is
 the preferable option.
 With regard to the optimization of insert performance, the highest possible
 batch size is the first choice.
 As real-time analysis only makes sense if the latest data is added to the
 database in real-time, the maximum turnaround time of meter readings is
 another constraint when chosing the best batch size.
 As trade-off of all this considerations, a batch size of 100,000 is chosen.
 That means that a new meter reading will be transported to the database
 system in under four seconds.
 
\end_layout

\begin_layout Standard
The CPU load of this configuration varies between 30% and 110%.
 This leaves enough ressources for the simultaneous execution of analytical
 queries which is investigated in another thesis 
\begin_inset CommandInset citation
LatexCommand cite
key "steffen"

\end_inset

.
 The execution time after 1000 inserts averages 410ms in this scenario.
 That means that the target insert rate of 112,000 readings per second which
 is required to process the 100 million smart meters could be outperformed
 considerably.
 It is important to note that this time measurement is even falsified by
 a deficient implementation of the merge process (cf.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Restraining-Disaster-Recovery"

\end_inset

) which blocks pending INSERT statements during a merge although it should
 be carried out asynchronously 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/dasfaa/KrugerGTPZF10"

\end_inset

.
\end_layout

\begin_layout Standard
During the execution of the simulation, three main problems became manifest.
 First of all, early implementations of the database client weren't performant
 enough to insert the incoming meter readings fast enough to avoid congestion.
 The measures that were taken to solve this problem are explained in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Acceleration-of-INSERT"

\end_inset

.
 Secondly, first projections of the required amount of main memory for the
 depicted scenario were too high to allow for a real world implementaion,
 which lead to the investigation of compression potentials presented in
 Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Compression"

\end_inset

.
 In the third place, the execution time of the merge process turned out
 to grow exponentially with the size of the dataset.
 But since Krüger et.
 al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/dasfaa/KrugerGTPZF10"

\end_inset

 have already shown that the merge process can be carried out in linear
 dependency of the size of the dataset, this problem isn't considered in
 this thesis.
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Acceleration-of-INSERT"

\end_inset

Acceleration of INSERT-Statements
\end_layout

\begin_layout Standard
In order to support a constant data stream originating from as many smart
 meters as possible, it is important to reduce the execution time of INSERT-stat
ements to the greatest possible extent.
 The measures that have been taken into consideration for that reason are
 depicted and evaluated in this section.
\end_layout

\begin_layout Standard
Unless stated otherwise, all measurements in this section have been made
 under the following conditions: The database client is running on host
 HPC and connecting to a NewDB instance on host HPA via JDBC.
 The hosts are connected via Gigabit LAN.
 The execution of INSERT-statements takes place on empty tables, whereas
 each table is generated before and droped after each test run.
 Autocommit is disabled as well as automerge and merge times are not included
 in the measurements.
 Transactional logging isn't in effect during inserts.
 Time measurements are taken with the help of the Java getTimeInMillis()-API
 
\begin_inset CommandInset citation
LatexCommand cite
key "java/time"

\end_inset

.
\end_layout

\begin_layout Standard
Three different schemas have been used for the measurements.
 The schema READINGS_PK (Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Schema-READINGS_PK"

\end_inset

) constitutes a regular column table with a natural primary key on the columns
 meterid and timestamp.
 The schema READINGS_IO_PK (Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Schema-READINGS_IO_PK"

\end_inset

) is equivalent to READINGS_PK, except that it represents an insert-only
 column table.
 The third schema is READINGS_IO (Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Schema-READINGS_IO"

\end_inset

), which is an insert-only column table with omitted explicit primary key.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\sffamily},breaklines=true,captionpos=b,float,frame=single,language=SQL,showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lis:Schema-READINGS_PK"

\end_inset

Schema READINGS_PK
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

CREATE COLUMN TABLE readings (meterid INTEGER, timestamp INTEGER, value
 INTEGER, PRIMARY KEY (meterid, timestamp))
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\sffamily},breaklines=true,captionpos=b,float,frame=single,language=SQL,showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lis:Schema-READINGS_IO_PK"

\end_inset

Schema READINGS_IO_PK
\end_layout

\end_inset

CREATE INSERT ONLY COLUMN TABLE readings (meterid INTEGER, timestamp INTEGER,
 value INTEGER, PRIMARY KEY (meterid, timestamp))
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\sffamily},breaklines=true,captionpos=b,float,frame=single,language=SQL,showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lis:Schema-READINGS_IO"

\end_inset

Schema READINGS_IO
\end_layout

\end_inset

CREATE INSERT ONLY COLUMN TABLE readings (meterid INTEGER, timestamp INTEGER,
 value INTEGER)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Prepared-Statements"

\end_inset

Prepared Statements
\end_layout

\begin_layout Standard
The naive approach to insert multiple rows into a table is to execute single
 insert statements sequentially.
 The problem in doing so is that parsing and the generation of an execution
 plan is carried out again for each statement, although they are equivalent.
 The solution to this issue is the utilization of prepared statements.
 As its name implies, afore-mentioned tasks get executed only once and the
 statement can be reused for subsequent inserts.
 
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:naive-insert"

\end_inset

 compares the performance of the usage of standard and prepared statements.
 First, 100,000 readings have been inserted into an empty instance of READINGS_P
K by generating a new statement for each reading.
 After 10 runs, the total insert time averages 3 minutes 38.530 seconds (standard
 deviation: 3.281 seconds).
 When repeating the measurement using a prepared statement, the average
 insert time gets reduced to 51.974 seconds (standard deviation: 365ms),
 which is equivalent to a speed-up of almost 80%.
 With relation to the clear difference, the relatively small number of measureme
nt iterations and the high standard deviation are still sufficient to emphasize
 the statement.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/naive-prepared.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:naive-insert"

\end_inset

Comparison of standard and prepared statements
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Batch Inserts
\end_layout

\begin_layout Standard
As an extension of prepared statements, most database interfaces offer a
 possibility to execute batches of the same statement at once.
 The executeBatch method implemented by JDBC 
\begin_inset CommandInset citation
LatexCommand cite
key "java/statement"

\end_inset

 or the array binding capabilities offered by ODBC 
\begin_inset CommandInset citation
LatexCommand cite
key "msdn/arrayBinding"

\end_inset

 are examples for such functionality.
 
\end_layout

\begin_layout Standard
In contrast to the execution of 100,000 prepared, but discrete inserts (average:
 51.974 seconds, standard deviation: 365ms), the insert time can be further
 reduced to 646ms (standard deviation: 33ms) with the help of batch insert
 mechanisms, a speed-up of 99%.
 In the case of batch inserts, the measurement was determined through 1000
 runs and the measured time includes the generation and execution of a single
 prepared statement containing 100,000 rows, as well as a single commit
 at the end of the transaction.
 As with the measurement in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Prepared-Statements"

\end_inset

, an empty instance of READINGS_PK was used for every run.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/prepared-batch.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Comparison of prepared statements and prepared batches
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Omission-of-Natural"

\end_inset

Omission of Natural Keys
\end_layout

\begin_layout Standard
When investigating the nature of a smart-meter reading, it becomes evident
 that the combination of its meter id and timestamp form a natural key that
 uniquely identifies each row.
 This key could very well serve as primary key for the table, as no two
 readings originating from the same meter may exist for a given point of
 time.
 However, this means that when inserting rows, time expensive tests on key
 violations would have to be performed.
 At the same time, there are no big drawbacks of allowing duplicate readings.
 Provided that meters normally don't record one point of time twice, saving
 such exceptional records might even be helpful for fraud and failure detection.
 Furthermore, keeping track of records might be a legal requirement in many
 countries 
\begin_inset CommandInset citation
LatexCommand cite
key "HPI/GrundKTZ/CeFda"

\end_inset

.
\end_layout

\begin_layout Standard
The employed database system allows column tables without explicit primary
 key only in the form of so-called insert-only tables.
 As the name already suggests, records can only be added to a insert-only
 table, but neither be updated or deleted.
 These constraints can be accepted, since concurrent readings could be distingui
shed by timestamps or valid/invalid-flags and there are no reasons for frequent
 updates.
 Insert-only tables make use of an implicit row id as primary key which
 is comparable to auto-increment fields.
 While increasing the consumed amount of memory through this additional
 column, a considerable reduction of insert times can be achieved through
 this approach.
\end_layout

\begin_layout Standard
To evaluate the costs of explicit keys, batches of 100,000 readings have
 been inserted into the schemas READINGS_PK, READINGS_IO_PK and READINGS_IO.
 In each case, the measured time includes the generation of a prepared statement
 containing 100,000 rows, the execution of this statement on an empty table
 and a single commit at the end of this transaction.
 All three measurements have been repeated 1000 times.
\end_layout

\begin_layout Standard
The results are depicted in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Insert-Only"

\end_inset

.
 Insertion into a regular column table with explicit primary key takes an
 average of 646ms (standard deviation: 33ms).
 Insert-only tables with an explicit primary key are only marginally faster,
 with an average of 612ms (standard deviation: 32ms).
 In contrast, insertions into a table without any explicit keys average
 166ms, with a standard deviation of 16ms.
 That means that insert times can be reduced by approximately 76% through
 the omission of unnecessary keys.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/insert-only.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Insert-Only"

\end_inset

Comparison of insert performance of tables with and without explicit primary
 key
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Restraining-Disaster-Recovery"

\end_inset

Restraining Disaster Recovery
\end_layout

\begin_layout Standard
Transacation logs are an important measure to safeguard the compliance of
 the ACID properties, particularly with regard to atomicity and durability
 
\begin_inset CommandInset citation
LatexCommand cite
key "Haerder:1983:PTD:289.291"

\end_inset

.
 However, one could imagine to give up parts of the ACID properties in exchange
 for performance benefits due to the supposed architecture of an advanced
 metering infrastructure.
 In particular, the ability to answer requests of meter readings on demand
 is ranked as minimum requirement for smart meters 
\begin_inset CommandInset citation
LatexCommand cite
key "openmeter/requirements"

\end_inset

, which can store the reading history of at least one year at the same time.
 This implies that it might be feasible to accept the loss of recent meter
 readings in the case of a database failure, since they could just be requested
 again.
\end_layout

\begin_layout Standard
The used database system splits up column stores into a read-optimized main
 store and a write-optimized differential buffer.
 New rows are inserted into the differential buffer and transfered to the
 main store during the so-called merge process 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/dasfaa/KrugerGTPZF10,HPI/GrundKPWZ/BmGOI"

\end_inset

.
 If strict ACID compliance is desired, both of these structures have to
 be recovered in the case of a failure.
 However, all records are written to a non-volatile medium during the merge
 process, which means that the persistency of the main store is not depending
 on transaction logs once the merge is complete.
 From this follows that the impact of missing logs of the insert process
 itself is rather noncritical.
 In the worst case, all meter readings which haven't been merged yet would
 be lost temporarily.
\end_layout

\begin_layout Standard
The schema READINGS_IO was used to measure the impact of transaction logs
 on insert performance.
 Again, the measured time includes the generation of a prepared statement
 containing 100,000 rows, its execution on an empty table and a single commit
 at the end of this transaction.
 The measurement has been repeated 1000 times.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Logging"

\end_inset

 shows the results of this measurements.
 With activated logging, inserts average 177ms (standard deviation: 18ms).
 The same inserts take averagely 166ms (standard deviation: 16ms) when logging
 is disabled.
 In other words, transaction logs slow down the insert process by approximately
 6%.
 Consequently, abandoning transaction logs for insertions can be considered
 doubtful for real world applications.
 The performance gain doesn't compensate the lost ability to recover unmerged
 readings in the case of a system failure.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/logging.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Logging"

\end_inset

Impact of transactional logging on insert performance
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Parallel Execution of INSERT-Statements
\end_layout

\begin_layout Standard
In order to allow for a better evaluation of the impact of parallel inserts,
 a bigger dataset of 10,200,000 rows has been inserted into the Table READINGS_I
O.
 The time measurement, which begins with the start of the first and ends
 with the return of the last spawned thread has been repeated 1000 times
 for 
\begin_inset Formula $n$
\end_inset

 threads, with 
\begin_inset Formula $n\in\{1,3,6,12\}$
\end_inset

.
 Thereby, the dataset is divided equally to all threads and each thread
 establishes a JDBC connection to the database and executes a single prepared
 insert statement containing 
\begin_inset Formula $\frac{10,200,000}{n}$
\end_inset

 rows.
 Every thread initiates a commit before returning, so the measured time
 includes 1 commit for 
\begin_inset Formula $n=1$
\end_inset

 and 12 commits for 
\begin_inset Formula $n=12$
\end_inset

.
 The server HPA which hosts the database has a total of 12 cores.
\end_layout

\begin_layout Standard
The results of the measurement are depicted in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:parallelisation"

\end_inset

.
 The insert time using one thread averages 29.935 seconds, with a standard
 deviation of 547ms.
 Based on this value, the theoretical optimum behaviour is plotted as 
\begin_inset Formula $\frac{v_{t-1}}{2}$
\end_inset

 for a number of 
\begin_inset Formula $t$
\end_inset

 threads and the projected time measurement 
\begin_inset Formula $v_{t-1}$
\end_inset

 of the preceding number of threads.
 In theory and without considering the overhead of multithreading, the insert
 process should take roughly 2.5 seconds when using 12 threads provided that
 it can be parallelized completely.
 The actual value is 4.248 seconds (standard deviation: 168ms).
 Considering the fact that database overhead like the increased commit number
 and the system overhead of multithreading is induced, it can be said that
 the insert time scales almost perfectly with the number of threads and
 cores.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/parallel.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:parallelisation"

\end_inset

Performance gain by parallel execution of INSERT-statements
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Compression"

\end_inset

Compression
\end_layout

\begin_layout Standard
Data volumes like the ones involved in a smart metering infrastructure entail
 the need for data compression.
 Since data of the same type is stored in continuous blocks, column stores
 are particularly suited for this task 
\begin_inset CommandInset citation
LatexCommand cite
key "Abadi:2008:QEC:1467436"

\end_inset

.
 
\end_layout

\begin_layout Standard
Heavyweight compression algorithms like Huffman coding 
\begin_inset CommandInset citation
LatexCommand cite
key "huf52"

\end_inset

, arithmetic coding 
\begin_inset CommandInset citation
LatexCommand cite
key "Witten:1987:ACD:214762.214771"

\end_inset

 or the LZW algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Welch:1984:THD:1319729.1320134"

\end_inset

 which give up compression and decompression speed to increase compression
 ratio typically result in performance losses.
 With insert performance beeing a crucial part of the depicted scenario,
 the focus of this paper is on lightweight column compression techniques.
 An overview over available techniques is given in the next section in order
 to make an evaluation in the context of energy event data possible.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Lightweight-Column-Compression"

\end_inset

Lightweight Column Compression Techniques
\end_layout

\begin_layout Standard
The lightweight column compression techniques which are presented in the
 following can be divided into three groups.
 Domain coding replaces values of any type by shorter ordinal references
 and is the underlying basis of all other methods.
 Common value suppression techniques like prefix coding and sparse coding
 and in a broader sense run-length encoding and cluster coding try to replace
 frequent values by shorter representations.
 Indirect coding introduces local dictionaries to reduce the width of references
 further.
\end_layout

\begin_layout Standard
Particularly domain and indirect coding would be pointless if full integer
 widths would have to be used to store values.
 For that reason, they rely on techniques to reduce value width.
 These include bit compression 
\begin_inset CommandInset citation
LatexCommand cite
key "sanders:intersection"

\end_inset

, variable byte coding 
\begin_inset CommandInset citation
LatexCommand cite
key "Silva:2000:FFW:348751.348754"

\end_inset

 and patched frame-of-reference compression 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1109/ICDE.2006.150"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Domain Coding
\end_layout

\begin_layout Standard
Domain coding or dictionary compression 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09,Abadi:2006:ICE:1142473.1142548,HPI/PlattnerZ/nHdai,Lemke:2010:SUQ:1881923.1881936"

\end_inset

 is the fundamental compression algorithm which is utilized regardless of
 data types and structures and independently from other compression algorithms.
 All original values of a column are stored in a sorted dictionary and the
 column itself is represented as index vector consisting of ordinal references
 to this dictionary.
 According to 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09"

\end_inset

, the memory footprint (in bits) of a domain coded column containing 
\begin_inset Formula $d$
\end_inset

 distinct values of an arbitrary type and a total of 
\begin_inset Formula $t$
\end_inset

 values can be calculated by formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:domain-coding"

\end_inset

.
 
\begin_inset Formula 
\begin{equation}
t\cdot\lceil\log_{2}(d)\rceil\label{eq:domain-coding}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The size of the dictionary itself has to be added to the total amount of
 required main memory, which carries weight especially when the record set
 contains a high percentage of distinct values.
 
\end_layout

\begin_layout Standard
Aside from the reduction of memory consumption, this method also entails
 an acceleration of processing speed due to the handling of smaller data
 volumes on a per request basis and the optimization of processing units
 for ordinal types on the hardware layer.
\end_layout

\begin_layout Subsubsection
Prefix Coding
\end_layout

\begin_layout Standard
Prefix coding 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09,HPI/PlattnerZ/nHdai,Lemke:2010:SUQ:1881923.1881936"

\end_inset

 is powerful in such cases where a column contains one specific value very
 often (e.g.
 the NULL-value) and the table can be sorted by this column such that this
 value occurs at the beginning of this column.
 The prefix of equal values is then removed from the index vector completely.
 The prefix value and the number of occurrences are saved separately, each
 with a consumption of 32 bits.
 Lemke et.
 al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09"

\end_inset

 have shown that the space requirements (in bits) of a prefix coded column
 with a total of 
\begin_inset Formula $t$
\end_inset

 elements, 
\begin_inset Formula $d$
\end_inset

 distinct values and a prefix of 
\begin_inset Formula $p$
\end_inset

 elements thus can be calculated by formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:prefix"

\end_inset

.
 
\begin_inset Formula 
\begin{equation}
(t-p)\cdot\lceil\log_{2}(d)\rceil+64\label{eq:prefix}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Sparse Coding
\end_layout

\begin_layout Standard
If the occurences of the most frequent value are spread throughout a column,
 sparse coding 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09,HPI/PlattnerZ/nHdai,Lemke:2010:SUQ:1881923.1881936"

\end_inset

 can be used to reduce the size of this column.
 In doing so, all occurences of the value are removed from the index vector
 and this so-called sparse value is saved once as reference into the dictionary,
 consuming 32 bits.
 A bit vector is generated for the column, indicating whether the value
 corresponding to the element at the given index equals the sparse value
 or not.
 In addition, a prefix coding is applied to this bit vector.
 According to 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09"

\end_inset

, sparse compression reduces the size of a column with 
\begin_inset Formula $s$
\end_inset

 occurences of the sparse value to the number of bits deduced from formula
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:sparse"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
(t-s)\cdot\lceil\log_{2}(d)\rceil+(t-p)+32\label{eq:sparse}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
To retrieve a value from a sparse encoded column, the bit vector has to
 be checked at the given index.
 If it indicates that the value differs from the sparse value, the index
 of the actual value within the index vector can be retrieved through the
 number of set bits up to the given index.
\end_layout

\begin_layout Subsubsection
Cluster Coding
\end_layout

\begin_layout Standard
When applying cluster coding 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09,HPI/PlattnerZ/nHdai,Lemke:2010:SUQ:1881923.1881936"

\end_inset

, the index vector gets divided into equally sized blocks.
 All blocks which contain only one distinct value are then compressed by
 removing all but one occurence of the value within this block from the
 index vector.
 In addition, a bit vector is generated which indicates whether a block
 has been compressed or not.
 
\end_layout

\begin_layout Standard
Cluster coding is applicable in cases where a column contains only few distinct
 values which form blocks innately.
 For instance, a column containing the alternating values 1, 2 and 3 would
 be the worst case for cluster coding.
 To calculate the memory footprint (in bits) of a cluster coded column with
 a total of 
\begin_inset Formula $t$
\end_inset

 and 
\begin_inset Formula $d$
\end_inset

 distinct values, formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:cluster"

\end_inset

 has been deduced (where 
\begin_inset Formula $b$
\end_inset

 is the block size and 
\begin_inset Formula $b\mid t$
\end_inset

).
 
\begin_inset Formula 
\begin{equation}
\frac{t}{b}\cdot\lceil\log_{2}(d)\rceil+\frac{t}{b}\label{eq:cluster}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Indirect Coding
\end_layout

\begin_layout Standard
Just like cluster coding, indirect coding 
\begin_inset CommandInset citation
LatexCommand cite
key "conf/btw/LemkeSF09,HPI/PlattnerZ/nHdai,Lemke:2010:SUQ:1881923.1881936"

\end_inset

 is based on a division of the index vector into blocks of equal size.
 However, a domain coding of these blocks takes place.
 Thus, every block can have its own dictionary as additional level of indirectio
n between the actual value stored in the global dictionary and the bit vector
 pointing to this value from the index vector.
 Sharing dictionaries among subsequent blocks is possible as long as adding
 new values to the dictionary wouldn't increase the size of the bit vector
 representing the key.
 Furthermore, blocks with a high percentage of distinct values still can
 use the global dictionary directly.
\end_layout

\begin_layout Standard
Such beeing the case, indirect coding is particularly powerful in columns
 which contain blocks with few distinct values.
\end_layout

\begin_layout Subsubsection
Run-Length Encoding
\end_layout

\begin_layout Standard
Run-length encoding is a very simple lossless compression algorithm which
 unfolds its full potential in sorted columns.
\end_layout

\begin_layout Standard
According to the approach published by Golomb 
\begin_inset CommandInset citation
LatexCommand cite
key "Golomb66"

\end_inset

, sequences of a value (so-called 
\begin_inset Quotes eld
\end_inset

runs
\begin_inset Quotes erd
\end_inset

) are replaced by a single occurence of this value and the length of the
 original sequence.
 Due to read performance losses, this method is not applicable for column
 stores in its original form, as all preceding values of a given index would
 have to be touched in order to find the actual value.
\end_layout

\begin_layout Standard
For this reason, the technique used in column stores is slightly different
 
\begin_inset CommandInset citation
LatexCommand cite
key "HPI/PlattnerZ/nHdai"

\end_inset

.
 To compress a column, all contiguous subsequent occurences of a value are
 removed from the index vector.
 Additionally, a second vector is generated.
 It contains the starting index of the index vectors corresponding entry.
 Formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:run-length"

\end_inset

 has been deduced to calculate the size (in bits) of a 
\emph on
sorted
\emph default
 column containing a total of 
\begin_inset Formula $t$
\end_inset

 and 
\begin_inset Formula $d$
\end_inset

 distinct values which is compressed by run-length encoding.
 
\begin_inset Formula 
\begin{equation}
d\cdot\lceil\log_{2}(d)\rceil+d\cdot\lceil\log_{2}(t)\rceil\label{eq:run-length}
\end{equation}

\end_inset

Searching a given index becomes less complex compared to the original algorithm
 due to the modification mentioned above.
 For instance, it can be carried out in logarithmic time by binary search.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Compression-of-Energy"

\end_inset

Compression of Energy Event Data
\end_layout

\begin_layout Standard
With due regard to the available compression techniques outlined in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Lightweight-Column-Compression"

\end_inset

, the process of minimizing the space requirements of smart-meter readings
 comes down to three tasks.
 First, the number of distinct values has to be reduced as far as possible
 without losing relevant information in order to unfold the full potential
 of dictionary compression.
 Secondly, the spreading of values has to be analyzed in order to evaluate
 potential benefits of common value suppression techniques.
 And in the third place, the readings have to be sorted in such a way that
 contiguous blocks of equal values which are as wide as possible occur.
 As mentioned in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:AMI-Implementation"

\end_inset

, the assumed model of meter readings consists of the three columns meter
 id, timestamp and value.
\end_layout

\begin_layout Subsubsection
Reducing the Number of Distinct Values
\end_layout

\begin_layout Standard
When investigating the necessary number of distinct values, the meter id
 column can be ruled out quickly.
 Obviously, there have to be exactly as many distinct ids as there are smart-met
ers known to the system.
 Furthermore, the specific characteristics aren't an issue due to dictionary
 compression, so the natural implementation as integer in the interval 
\begin_inset Formula $[1,n]$
\end_inset

 can be chosen, where 
\begin_inset Formula $n$
\end_inset

 is the number of smart meters.
\end_layout

\begin_layout Standard
The situation is different with the timestamp column.
 In a first approach, timestamps exact to the second have been used, yielding
 
\begin_inset Formula $365\cdot24\cdot60\cdot60=31,536,000$
\end_inset

 distinct values per year.
 But the relevant information for energy providers besides the consumption
 value is if there is a meter reading for a given time slot or not, and
 this information can be gained with less accurate timestamps.
 Even real-time analysis scenarios like the calculation of the current consumpti
on of all customers can be carried out without the need of timestamps exact
 to the second.
 In this specific example, it would be sufficient to build the sum of all
 known timestamps of a given time slot.
\end_layout

\begin_layout Standard
Hence, it is acceptable to reduce the resolution of the saved timestamps
 to the one of the measurement interval.
 This means that the timestamps can be rounded down to 15 minute intervals.
 For example, 08:21:30 can be replaced by 08:15:00.
 One could as well save sequences instead of such timestamps, e.g.
 as ordinal reference to the quarter of an hour slot of a day, but since
 domain coding has exactly this effect, the additional logic doesn't have
 to be implemented manually.
 This strategy yields 
\begin_inset Formula $365\cdot24\cdot4=35,040$
\end_inset

 distinct values per year, which is a saving of 99.9% compared to the inital
 approach.
 In the abstract, the required amount of space could be reduced by truncating
 the timestamps.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Sample-readings"

\end_inset

 shows that at least the last two digits of a timestamp are always 
\begin_inset Formula $00$
\end_inset

, so stripping them would be a reversible operation.
 Through this procedure, 7 bits could be saved per timestamp.
 However, this means savings of no more than roughly 30KB per year since
 every value is saved in the dictionary only once, which isn't profitable.
\end_layout

\begin_layout Standard
The consumption information in the value column can be saved in two ways.
 One possibility is to save counter readings, that means every reading contains
 the total amount of consumed energy since the installation of the meter.
 The other possibility is to save consumption deltas.
 If the counter readings of two subsequent time slots are 
\begin_inset Formula $v_{t-1}$
\end_inset

 and 
\begin_inset Formula $v_{t}$
\end_inset

, the value that would be saved for the time slot 
\begin_inset Formula $t$
\end_inset

 would be 
\begin_inset Formula $v_{t}-v_{t-1}$
\end_inset

 in the case of consumption deltas.
 The two strategies are equivalent, as the sum of all deltas yields the
 counter reading, and the deltas can be calculated by subtracting subsequent
 counter readings.
 The question remains which approach requires less distinct values.
\end_layout

\begin_layout Standard
According to 
\begin_inset CommandInset citation
LatexCommand cite
key "eu/measurement"

\end_inset

, power meters are measuring kilowatt hours and are calibrated to three
 decimal places (watt hours).
 The consulting company Capgemini estimates a lifespan of eight years for
 smart-metering devices 
\begin_inset CommandInset citation
LatexCommand cite
key "capgemini/analyse"

\end_inset

.
 That means that residential customers with an average consumption of 1000kWh
 per year would produce around 
\begin_inset Formula $8\cdot1000\cdot1000=8,000,000$
\end_inset

 distinct counter readings over the period of a meters lifetime.
 
\end_layout

\begin_layout Standard
In analysing the H0 profile, which contains average consumption deltas of
 residential customers in 15 minute intervals, it can be determined that
 all values are in the interval of 
\begin_inset Formula $[0.001;0.067]$
\end_inset

 kWh.
 Since this profile is normalized to an annual consumption of 1000kWh, it
 can be compared directly to the calculation above.
 Even when taking huge deviations of the factor 100 or more into account,
 the number of distinct values is still only a fraction of those possible
 when saving counter readings.
 Therefore, it can be assumed that the number of distinct values can be
 reduced by 99.99% through the utilization of consumption deltas which thereby
 get the prefered option with regard to main memory consumption.
\end_layout

\begin_layout Subsubsection
Common Values
\end_layout

\begin_layout Standard
Since the meter id and timestamp column contain values wich are rather distribut
ed uniformly, the only column that could potentially benefit of common value
 suppression techniques is the value column.
 When taking the H0 profile as a basis, it turns out that some values indeed
 occur ten times more often than others.
 However, there is no single value which would qualify as universal most
 common value.
 Furthermore, it can be doubted that this phenomenon also becomes manifest
 in real consumption data since the profile is normalized.
 Accordingly, the common value suppression techniques prefix coding and
 sparse coding aren't practicable for energy event data.
\end_layout

\begin_layout Subsubsection
Finding the Optimal Ordering
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setlength{
\backslash
jot}{3mm+3pt}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In order to achieve the highest possible compression, the table has to be
 sorted in a manner that continuous blocks of equal values are formed, preferebl
y in all columns.
 To evaluate the memory footprint of the meter readings table, the performance
 is measured as a function of the number of smart meters 
\begin_inset Formula $n$
\end_inset

, with every smart meter having a record set of one year in 15 minute intervals.
 In the following, the memory footprint of the table 
\begin_inset Formula $S_{\mathrm{total}}$
\end_inset

 is analyzed per column, so the total capacity requirements can be calculated
 by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
S_{\mathrm{total}}(n) & =S_{\mathrm{id}}(n)+S_{\mathrm{datetime}}(n)+S_{\mathrm{value}}(n)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
which returns the minimum required number of bits for the chosen compression
 techniques.
 Thereby, the value column is assumed to contain at most 100 distinct values.
\end_layout

\begin_layout Standard
First of all, domain coding (cf.
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:domain-coding"

\end_inset

)) is applied to all columns.
 That means that there is a base compression on all columns which equals
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
S_{\mathrm{id}}(n) & =n\cdot35040\cdot\lceil\log_{2}(n)\rceil\label{eq:space-id}\\
S_{\mathrm{datetime}}(n) & =n\cdot35040\cdot\lceil\log_{2}(35040)\rceil\label{eq:space-datetime-1}\\
S_{\mathrm{value}}(n) & =n\cdot35040\cdot\lceil\log_{2}(100)\rceil\label{eq:space-value}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Nevertheless, the compression rate can be increased drastically by sorting
 and subsequent run-length encoding.
 In the abstract, all three columns qualify for a primary sorting.
 The goal is to form as few continuous blocks as possible.
 Sorting the table by the meter id yields 
\begin_inset Formula $n$
\end_inset

 blocks with a length of 35040.
 If sorted by the timestamp column, the result are 35040 blocks with each
 having a lenght of 
\begin_inset Formula $n$
\end_inset

.
 In comparison, there are only 100 blocks with an average length of 
\begin_inset Formula $\frac{n\cdot35040}{100}$
\end_inset

 when sorting the table by the value column.
 Hence, as run-length encoding gets more and more inefficient when the number
 of blocks increases, the value column is theoretically best suited for
 a run-length encoding.
\end_layout

\begin_layout Standard
However, one has to take into consideration that the domain coded timestamp
 column requires more space than the domain coded value column, since 
\begin_inset Formula $\lceil\log_{2}(35040)\rceil>\lceil\log_{2}(100)\rceil$
\end_inset

.
 In other words, the timestamp column consumes 
\begin_inset Formula $9\cdot n$
\end_inset

 more bits.
 This also applies to the meter id column for 
\begin_inset Formula $n>100$
\end_inset

.
 To solve the question if there are break-even points, the following auxiliary
 functions are used, where 
\begin_inset Formula $\mathrm{D}(n)$
\end_inset

 denotes the memory footprint of a domain coded column and 
\begin_inset Formula $\mathrm{RLE}(n)$
\end_inset

 the one of a run-length encoded column for 
\begin_inset Formula $n$
\end_inset

 smart meters:
\begin_inset Formula 
\begin{align}
\mathrm{D}_{\mathrm{id}}(n) & =n\cdot35040\cdot\lceil\log_{2}(n)\rceil\\
\mathrm{RLE}_{\mathrm{id}}(n) & =n\cdot\lceil\log_{2}(n)\rceil+n\cdot\lceil\log_{2}(n\cdot35040)\rceil\\
\mathrm{D}_{\mathrm{datetime}}(n) & =n\cdot35040\cdot\lceil\log_{2}(35040)\rceil\\
\mathrm{RLE_{datetime}(n)} & =35040\cdot\lceil\log_{2}(35040)\rceil+35040\cdot\lceil\log_{2}(n\cdot35040)\rceil\label{eq:datetime-RLE}\\
\mathrm{D_{value}(n)} & =n\cdot35040\cdot\lceil\log_{2}(100)\rceil\\
\mathrm{RLE_{value}(n)} & =100\cdot\lceil\log_{2}(100)\rceil+100\cdot\lceil\log_{2}(n\cdot35040)\rceil
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The question is if there is a solution to the following inequation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathrm{RLE_{value}}(n)+\mathrm{D_{datetime}}(n)\leq\mathrm{D_{value}}(n)+\mathrm{RLE_{datetime}}(n)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It turns out that the inequation is only true for 
\begin_inset Formula $n\in[0,128]$
\end_inset

.
 For 
\begin_inset Formula $n>128$
\end_inset

, sorting the table by the timestamp column has to be prefered.
 The same problem applies to the comparison of the meter id and timestamp
 column.
 Again, the question is which solution is true for
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathrm{RLE_{datetime}}(n)+\mathrm{D_{id}}(n)\leq\mathrm{D_{datetime}}(n)+\mathrm{RLE_{id}}(n)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This time, there is a break-even point at 
\begin_inset Formula $n=35040$
\end_inset

, or in other words the inequation is true for 
\begin_inset Formula $n\in[35040,\infty[$
\end_inset

.
 Hence, sorting by the timestamp column is preferable as soon as more than
 35040 smart meters are in the database.
 Thus, function (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:space-datetime-1"

\end_inset

) can be replaced by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
S_{\mathrm{datetime}}(n)=35040\cdot\lceil\log_{2}(35040)\rceil+35040\cdot\lceil\log_{2}(n\cdot35040)\rceil
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Now that the primary sorting of the table is by timestamp, no more compression
 techniques can be applied to the meter id column, since the number of distinct
 ids per timestamp block equals the length of this block.
 However, this doesn't apply to the value column, which could be sorted
 within the constraints of the primary sorting.
 Since there is a correlation between date and time and energy consumption,
 it can even be assumed that certain values accumulate at a specific date
 and time, which would qualify the column for a further run-length encoding.
 Since the column contains relatively few distinct values, applying an indirect
 coding and not sorting the column is conceivable as an alternative, too.
 As both scenarios can no longer be mapped reasonably as a function of the
 number of smart meters, the efficiency of both approaches has been evaluated
 experimentally.
\end_layout

\begin_layout Standard
In order to analyze the impact of both techniques, 10,000 profiles which
 conform to the conditions outlined in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Estimation-of-Consumption"

\end_inset

 have been inserted into the tables shown in Listings 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Table-READINGS_RLE"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Table-READINGS_INDIRECT"

\end_inset

.
 The result is depicted in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:RLE-vs-INDIRECT"

\end_inset

.
 The compression rate is based on the unmerged size of the column which
 is 321,482KB.
 With 1,912KB compared to 187,101KB, the run-length encoded column is almost
 100 times smaller than the one compressed with indirect coding.
 Consequently, the former is the prefered option for further compressing
 the table.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:RLE-vs-INDIRECT"

\end_inset

Compression rates and memory consumption of the value column with run-length
 encoding and indirect coding
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle" tabularwidth="80col%">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Table
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Compression Rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Consumption [KB]
\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
READINGS_RLE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.6%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1,912
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
READINGS_INDIRECT
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
41.8%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
187,101
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\sffamily},breaklines=true,captionpos=b,float,frame=single,language=SQL,showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lis:Table-READINGS_RLE"

\end_inset

Schema READINGS_RLE
\end_layout

\end_inset

CREATE INSERT ONLY COLUMN TABLE readings (meterid INTEGER, timestamp INTEGER,
 value INTEGER) WITH PARAMETERS ('COMPRESSION' = ('TIMESTAMP', 'RLE'), 'COMPRESS
ION' = ('VALUE', 'RLE'))
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\sffamily},breaklines=true,captionpos=b,float,frame=single,language=SQL,showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lis:Table-READINGS_INDIRECT"

\end_inset

Schema READINGS_INDIRECT
\end_layout

\end_inset

CREATE INSERT ONLY COLUMN TABLE readings (meterid INTEGER, timestamp INTEGER,
 value INTEGER) WITH PARAMETERS ('COMPRESSION' = ('TIMESTAMP', 'RLE'), 'COMPRESS
ION' = ('VALUE', 'INDIRECT'))
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the worst case, the memory footprint of the value column hence can be
 calculated by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
S_{\mathrm{value}}(n)=35040\cdot100\cdot\lceil\log_{2}(100)\rceil+35040\cdot100\cdot\lceil\log_{2}(n\cdot35040)\rceil\label{eq:value-RLE}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
which is still better than domain coding alone for 
\begin_inset Formula $n>442$
\end_inset

.
 The total amount of required memory thus can be estimated by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
S_{\mathrm{total}}(n) & =n\cdot35040\cdot\lceil\log_{2}(n)\rceil+\label{eq:s-total}\\
 & +35040\cdot\lceil\log_{2}(35040)\rceil+35040\cdot\lceil\log_{2}(n\cdot35040)\rceil+\nonumber \\
 & +35040\cdot100\cdot\lceil\log_{2}(100)\rceil+35040\cdot100\cdot\lceil\log_{2}(n\cdot35040)\rceil\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Standard
However, 
\begin_inset Formula $S_{\mathrm{total}}$
\end_inset

 doesn't cover system overhead like the row-id column (cf.
 Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Omission-of-Natural"

\end_inset

).
 Therefore, the real consumption has been measured in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Estimation-of-Consumption"

\end_inset

 in order to give a more realistic estimation of the memory footprint of
 energy event data.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Estimation-of-Consumption"

\end_inset

Estimation of Main Memory Consumption
\end_layout

\begin_layout Standard
To estimate the main memory consumption of large customer bases, profiles
 containing one year of readings have been generated with the assistance
 of the H0-profile.
 Each profile consists of 35040 readings, and the value 
\begin_inset Formula $r_{\mathrm{v}}$
\end_inset

 of each reading differs from the equivalent value 
\begin_inset Formula $v$
\end_inset

 from the H0 profile with a uniformly distributed variance such that 
\begin_inset Formula $0\leq v-v\cdot0,20\leq r_{\mathrm{v}}\leq v+v\cdot0,20$
\end_inset

.
 The smart-meter ids have been chosen from 
\begin_inset Formula $[1,n]$
\end_inset

, where 
\begin_inset Formula $n$
\end_inset

 is the number of generated profiles.
 However, the actual interval doesn't have a considerable effect on memory
 consumption due to the effects of dictionary compression.
 The year 2010 served as date range for the readings.
 
\end_layout

\begin_layout Standard
The profiles have been inserted and merged into the tables READINGS_IO and
 READINGS_RLE, so the measured memory footprint constitutes the size of
 the read-optimized main store.
 Since all rows have to be merged eventually to allow for real-time analyses,
 the consumption behaviour of the main store is the one that matters.
\end_layout

\begin_layout Subsubsection
Estimation for the Table READINGS_IO
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Footprint-IO"

\end_inset

 shows the memory footprint of the table READINGS_IO, which doesn't utilize
 any compression techniques besides domain coding.
 With the help of these measurements, the accuracy of the projection formula
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:domain-coding"

\end_inset

 for domain coded columns can be evaluated.
 The meter id column may server as an example.
 According to formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:domain-coding"

\end_inset

, it should require 584.80MB of main memory.
 The actual consumption differs from this value only by 30KB.
\end_layout

\begin_layout Standard
One can also see that the row id column, which is an implicit component
 of insert-only tables, is in no way optimized besides domain coding, since
 its footprint can be estimated very well by formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:domain-coding"

\end_inset

.
 The latter thus can be used to improve the projection of the total memory
 footprint of the table READINGS_IO for large 
\begin_inset Formula $n$
\end_inset

.
 Considering the already mentioned formulas 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:space-id"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:space-datetime-1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:space-value"

\end_inset

, the footprint projection for the table READINGS_IO can be calculated by
 formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:readings_io"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
S_{\mathrm{io}}(n) & =n\cdot35040\cdot\lceil\log_{2}(n)\rceil+n\cdot35040\cdot\lceil\log_{2}(35040)\rceil+\label{eq:readings_io}\\
 & +n\cdot35040\cdot\lceil\log_{2}(100)\rceil+n\cdot35040\cdot\lceil\log_{2}(n\cdot35040)\rceil\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Subsubsection
Estimation for the Table READINGS_RLE
\end_layout

\begin_layout Standard
The memory footprint of the table READINGS_RLE, which applies a run-length
 encoding to the timestamp and value columns, is depicted in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Footprint-RLE"

\end_inset

.
 When comparing the actual consumption values of the run-length compressed
 columns with the results from the formulas 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:datetime-RLE"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:value-RLE"

\end_inset

, it becomes evident that they have a much higher variance than the one
 for domain coding.
 For instance, the projected footprint of the timestamp column for 
\begin_inset Formula $n=10,000$
\end_inset

 is around 190KB, a deviation of almost 60%.
 The projected consumption of the value column for the same number of profiles
 is around ten times higher than the actual one, but formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:value-RLE"

\end_inset

 maps the worst case anyway.
 It has to be assumed that these deviations are resulting from overheads
 of the run-length compression implementation.
 Considering the fact that these two columns only add up to a fraction of
 the total memory footprint of roughly 0.1% for 
\begin_inset Formula $n=10,000$
\end_inset

, the approximation given by formulas 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:datetime-RLE"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:value-RLE"

\end_inset

 is still sufficient to project the footprint of the table READINGS_RLE
 for large 
\begin_inset Formula $n$
\end_inset

.
 Taking the already derivated formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:s-total"

\end_inset

 and the domain coding of the row id column into account, the footprint
 can be estimated with the help of formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:readings_rle"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
S_{\mathrm{rle}}(n)=S_{\mathrm{total}}+n\cdot35040\cdot\lceil\log_{2}(n\cdot35040)\rceil\label{eq:readings_rle}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Comparison to Storage on Disk
\end_layout

\begin_layout Standard
In order to give a comparison of space requirements with disk-based storage,
 the same profiles which were inserted into the database were saved as comma
 separated values in plain text files (ASCII encoded, one byte per character).
 Since the timestamp has a fixed length and the values hava an average of
 two digits, each line consists of a fixed part which adds up to 15 bytes,
 including separators and line break.
 The other part is the meter id, whose length varies.
 Assumed that the meter id lies in the interval mentioned above, the size
 (in bits) of a file containing one year profiles of 
\begin_inset Formula $n$
\end_inset

 smart meters can be projected with formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:CSV-size"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
S_{\mathrm{csv}}(n)=n\cdot35040\cdot15\cdot8+{\displaystyle \sum_{k=2}^{n+1}}\lceil\log_{10}(k)\rceil\cdot35040\cdot8\label{eq:CSV-size}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
A comparison of the three storage modes domain coded table, run-length compresse
d table and disk storage in CSV format is given in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:footprint-estimation"

\end_inset

.
 While the values for 10,000 profiles are actual measurements, the others
 are projections with the help of the formulas 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:readings_io"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:readings_rle"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:CSV-size"

\end_inset

.
 They show that the footprint of 10,000,000 profiles can be reduced by roughly
 65% compared to a storage on disk when making use of column compression
 potentials in in-memory databases.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Footprint-IO"

\end_inset

Memory footprint of table READINGS_IO for a number of smart meters 
\begin_inset Formula $n$
\end_inset

, broken down by column, in [MB]
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="6">
<features tabularvalignment="middle" tabularwidth="80col%">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10,000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="3mm" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meter ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.004$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.17$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2.92$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $41.76$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $584.83$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timestamp
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.20$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.80$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $6.82$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $66.97$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $668.45$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.03$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.29$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2.92$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $29.24$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $292.40$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="3mm">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Row ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.07$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.84$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $9.61$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $112.79$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1290.84$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="3mm" bottomspace="default">
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.31$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2.10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $22.28$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $250.78$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2836.53$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Footprint-RLE"

\end_inset

Memory footprint of table READINGS_RLE for a number of smart meters 
\begin_inset Formula $n$
\end_inset

, broken down by column, in [MB]
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="6">
<features tabularvalignment="middle" tabularwidth="80col%">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10,000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="3mm" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meter ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.004$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.17$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2.92$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $41.76$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $584.83$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Timestamp
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.27$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.28$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.29$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.30$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.32$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.09$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.71$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1.47$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1.71$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1.87$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="3mm">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Row ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.07$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.84$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $9.61$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $112.78$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1253.13$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="3mm" bottomspace="default">
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.43$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2.00$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $14.30$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $156.58$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1840.15$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:footprint-estimation"

\end_inset

Estimated space requirements of profiles containing one year of meter readings,
 on disk and in-memory
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features tabularvalignment="middle" tabularwidth="80col%">
<column alignment="left" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Profiles
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Size on disk
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Uncompressed
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Compressed
\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10,000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx6.2\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx2.8\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx1.8\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $100,000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx65\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx30\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx20\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1,000,000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx682\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx345\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx230\mathrm{GB}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $10,000,000$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx7.0\mathrm{TB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx3.8\mathrm{TB}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\approx2.5\mathrm{TB}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Impact-on-Insert"

\end_inset

Impact on Insert Performance
\end_layout

\begin_layout Standard
Graefe and Shapiro have shown that data compression can speed up operations
 rahter related to analytical queries 
\begin_inset CommandInset citation
LatexCommand cite
key "Graefe91datacompression"

\end_inset

.
 In contrast, it has to be assumed that compression does have a negative
 impact on inserts, or the merge process specifically.
 As compression isn't carried out on the write-optimized differential buffer,
 execution times of INSERT-statements aren't affected.
 However, a potentially expensive recompression has to be performed during
 each merge process.
\end_layout

\begin_layout Standard
In order to estimate the impact of the proposed compression strategy on
 the insert process, the execution time of the merge process has been measured
 for different base datasets.
 This base dataset, consisting of a number of profiles generated analogous
 to the ones in Sect.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Estimation-of-Consumption"

\end_inset

 is merged completely into the tables READINGS_IO and READINGS_RLE.
 Afterwards, another 100 profiles (3,504,000 rows) are inserted into the
 tables.
 Then, the time is measured it takes to merge the new records with the base
 dataset.
 The measurement was carried out on Host HPA and the database was configured
 to use at most four threads for the merge.
\end_layout

\begin_layout Standard
The results are depicted in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:merge-comparison"

\end_inset

.
 In contrast to the assumption, it shows clearly that a run-length encoding
 on the columns timestamp and value doesn't have a relevant impact on the
 merge process.
 One possible reason for this behaviour is that the compression overhead
 is compensated by the reduced data volume, which leads to a higher cache
 locality and reduced waiting time when reading data from main memory.
 
\end_layout

\begin_layout Standard
When merging with an empty table, the merge time averages 6033ms without
 run-length encoding (standard deviation: 54ms) and 6130ms (standard deviation:
 72ms) when applying this additional compression.
 If the table already contains 1000 profiles (350,40,000 rows), the merge
 takes an average of 3 minutes 15.680 seconds (standard deviation: 5.089 seconds)
 for the table READINGS_IO and 3 minutes 10.890 seconds (standard deviation:
 4.238 seconds) for the table READINGS_RLE.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename plots/merge.eps
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:merge-comparison"

\end_inset

Comparison of merge durations for different schemas and base datasets
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
By simulating the amount of meter readings that will arise when a smart
 metering infrastructure has been established in Germany it could be shown
 that this amount can be processed by an in-memory column store which utilizes
 a write optimized differential buffer.
 The target insert rate of 112,000 meter readings per second which corresponds
 to 100,000,000 smart meters could be outperformed significantly with the
 help of state-of-the-art hardware.
 The execution time of the insertion of 100,000 readings could be reduced
 to 170ms through the utilization of batch insert processing and insert-only
 tables, allowing for at least 500,000 inserts per second.
\end_layout

\begin_layout Standard
To achieve this insert rate, a trade-off between insert time and memory
 footprint had to be made.
 Insert-only tables can speed up the insertion by a factor of three compared
 to standard column tables since a natural primary key can be omitted.
 However, insert-only tables imply a row id column which can't be compressed
 further besides domain coding.
 This column makes up almost 70% of the total memory footprint of 1.8GB when
 storing 10,000 one year profiles.
 Thus, it might be preferable to give up the performance gain of insert-only
 tables if smaller customer bases have to be maintained.
\end_layout

\begin_layout Standard
Despite the increased footprint of insert-only tables, the amount of main
 memory which is required for the storage of meter readings could be reduced
 by 65% compared to a storage on disk by taking advantage of compression
 potentials in column stores.
 Lightweight column compression techniques were utilized solely to achieve
 this reduction.
 Since the compression overhead is compensated by the reduced data volume,
 the compression can be carried out without impairing the insert performance.
\end_layout

\begin_layout Standard
Even though not object of special attention, the merge process turned out
 to be the limiting factor.
 Although it can be carried out in linear dependency to the size of the
 dataset, the duration of the process would at some point outgrow the timespan
 until the size of the differential buffer induces the initiation of another
 merge.
 Thus, the implementation of data partitioning and aging strategies is inevitabl
e.
\end_layout

\begin_layout Standard
In conclusion, it can be said that the foundation for the real-time analysis
 of energy event data could be laid by an in-memory database.
 New possibilities which aren't realizable up to date arise.
 Amongst others, real-time pricing based on supply and demand 
\begin_inset CommandInset citation
LatexCommand cite
key "oli"

\end_inset

, short-term demand forecasting 
\begin_inset CommandInset citation
LatexCommand cite
key "julian"

\end_inset

 and the real-time visualization of energy consumption for consumers 
\begin_inset CommandInset citation
LatexCommand cite
key "romano"

\end_inset

 are feasible.
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section*
Appendix
\end_layout

\begin_layout Subsection*
Benchmark Environment
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="12" columns="3">
<features tabularvalignment="middle" tabularwidth="100col%">
<column alignment="left" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size scriptsize
Host HPA
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size scriptsize
Host HPB
\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
CPU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
2x Intel Xeon X5670 @ 2.93GHz
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
4x Intel Xeon X7560 @ 2.27GHz
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Main Memory
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
144GB @ 800MHz
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
256GB @ 1333MHz
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Operating System
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
openSUSE 11.2 2.6.31.14-0.8 (x64)
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Network Connectivity
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
82575EB Gigabit LAN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
NX3031 10-Gigabit LAN
\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
NewDB Version
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
1.50.00.327452 (dev)
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="2mm">
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="2mm">
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size scriptsize
Host HPC
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="2mm" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
CPU
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Intel Core i5 750 @ 2.67GHz
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Main Memory
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
8GB @ 1333MHz
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Operating System
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
openSUSE 11.3 2.6.34.8-0.2 (x64)
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row topspace="default" bottomspace="default">
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
Network Connectivity
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
82578DM Gigabit LAN
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "thesis"
options "C:/Users/Leo/AppData/Roaming/MiKTeX/2.9/tex/latex/lncs/splncs03"

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
thispagestyle{empty} 
\backslash
chapter*{Eigenst
\backslash
"andigkeitserkl
\backslash
"arung}
\end_layout

\begin_layout Plain Layout

Ich erkl
\backslash
"are hiermit, dass ich die vorliegende Arbeit selbst
\backslash
"andig verfasst und  keine anderen als die genannten Quellen und Hilfsmittel
 verwendet habe.
\backslash

\backslash
 
\backslash
vspace{2.0cm}
\backslash

\backslash
 Potsdam, den 30.
 Juni 2011 
\backslash
vspace{1.0cm}
\backslash

\backslash
 Leonhard Schweizer
\end_layout

\end_inset


\end_layout

\end_body
\end_document
